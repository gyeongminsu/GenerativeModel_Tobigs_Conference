{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-2.3.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: transformers in /gpfs/home2/kkms4641/miniconda3/envs/diffusion/lib/python3.9/site-packages (4.42.3)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting roboflow==0.2.7\n",
      "  Downloading roboflow-0.2.7.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting evaluate\n",
      "  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting certifi==2021.5.30 (from roboflow==0.2.7)\n",
      "  Downloading certifi-2021.5.30-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting chardet==4.0.0 (from roboflow==0.2.7)\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting cycler==0.10.0 (from roboflow==0.2.7)\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl.metadata (722 bytes)\n",
      "Collecting glob2 (from roboflow==0.2.7)\n",
      "  Downloading glob2-0.7.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting idna==2.10 (from roboflow==0.2.7)\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting Pillow==8.4.0 (from roboflow==0.2.7)\n",
      "  Downloading Pillow-8.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting kiwisolver==1.3.1 (from roboflow==0.2.7)\n",
      "  Downloading kiwisolver-1.3.1-cp39-cp39-manylinux1_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting matplotlib (from roboflow==0.2.7)\n",
      "  Downloading matplotlib-3.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /gpfs/home2/kkms4641/miniconda3/envs/diffusion/lib/python3.9/site-packages (from roboflow==0.2.7) (1.26.4)\n",
      "INFO: pip is looking at multiple versions of roboflow to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[31mERROR: Ignored the following yanked versions: 3.4.11.39, 3.4.11.41, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.5.2.52, 4.5.5.62, 4.7.0.68, 4.8.0.74\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python-headless==4.1.2.30 (from roboflow) (from versions: 3.4.10.37, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.14.51, 3.4.14.53, 3.4.15.55, 3.4.16.59, 3.4.17.61, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.46, 4.5.1.48, 4.5.2.54, 4.5.3.56, 4.5.4.58, 4.5.4.60, 4.5.5.64, 4.6.0.66, 4.7.0.72, 4.8.0.76, 4.8.1.78, 4.9.0.80, 4.10.0.82, 4.10.0.84)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv-python-headless==4.1.2.30\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-lightning transformers datasets roboflow==0.2.7 evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch_lightning'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# !pip install pytorch-lightning transformers datasets roboflow==0.2.7 evaluate\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mearly_stopping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_checkpoint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelCheckpoint\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_lightning'"
     ]
    }
   ],
   "source": [
    "# !pip install pytorch-lightning transformers datasets roboflow==0.2.7 evaluate\n",
    "\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "from roboflow import Roboflow\n",
    "\n",
    "rf = Roboflow(api_key=\"Oibac5vmVCCmRtFrRdIB\")\n",
    "project = rf.workspace(\"wan-kin-mun-hpzwo\").project(\"dog-segmentation\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"png-mask-semantic\")\n",
    "\n",
    "class SemanticSegmentationDataset(Dataset):\n",
    "    def __init__(self, root_dir, feature_extractor):\n",
    "        self.root_dir = root_dir\n",
    "        self.feature_extractor = feature_extractor\n",
    "\n",
    "        self.classes_csv_file = os.path.join(self.root_dir, \"_classes.csv\")\n",
    "        with open(self.classes_csv_file, 'r') as fid:\n",
    "            data = [l.split(',') for i, l in enumerate(fid) if i != 0]\n",
    "        self.id2label = {int(x[0]): x[1] for x in data}\n",
    "\n",
    "        image_file_names = [f for f in os.listdir(self.root_dir) if '.jpg' in f]\n",
    "        mask_file_names = [f for f in os.listdir(self.root_dir) if '.png' in f]\n",
    "\n",
    "        self.images = sorted(image_file_names)\n",
    "        self.masks = sorted(mask_file_names)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(os.path.join(self.root_dir, self.images[idx])).convert(\"RGB\")\n",
    "        segmentation_map = Image.open(os.path.join(self.root_dir, self.masks[idx])).convert(\"L\")\n",
    "\n",
    "        encoded_inputs = self.feature_extractor(images=image, segmentation_maps=segmentation_map, return_tensors=\"pt\")\n",
    "\n",
    "        for k, v in encoded_inputs.items():\n",
    "            encoded_inputs[k].squeeze_()  # remove batch dimension\n",
    "\n",
    "        return encoded_inputs\n",
    "\n",
    "class SegformerFinetuner(pl.LightningModule):\n",
    "    def __init__(self, id2label, train_dataloader=None, val_dataloader=None, test_dataloader=None, metrics_interval=100):\n",
    "        super(SegformerFinetuner, self).__init__()\n",
    "        self.id2label = id2label\n",
    "        self.metrics_interval = metrics_interval\n",
    "        self.train_dl = train_dataloader\n",
    "        self.val_dl = val_dataloader\n",
    "        self.test_dl = test_dataloader\n",
    "\n",
    "        self.num_classes = len(id2label.keys())\n",
    "        self.label2id = {v: k for k, v in self.id2label.items()}\n",
    "\n",
    "        self.model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "            \"nvidia/segformer-b0-finetuned-ade-512-512\",\n",
    "            return_dict=False,\n",
    "            num_labels=self.num_classes,\n",
    "            id2label=self.id2label,\n",
    "            label2id=self.label2id,\n",
    "            ignore_mismatched_sizes=True,\n",
    "        )\n",
    "\n",
    "        self.train_mean_iou = load_metric(\"mean_iou\")\n",
    "        self.val_mean_iou = load_metric(\"mean_iou\")\n",
    "        self.test_mean_iou = load_metric(\"mean_iou\")\n",
    "\n",
    "        self.val_outputs = []\n",
    "        self.test_outputs = []\n",
    "\n",
    "    def forward(self, images, masks):\n",
    "        outputs = self.model(pixel_values=images, labels=masks)\n",
    "        return outputs\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        images, masks = batch['pixel_values'], batch['labels']\n",
    "        outputs = self(images, masks)\n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "\n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits,\n",
    "            size=masks.shape[-2:],\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False\n",
    "        )\n",
    "\n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "\n",
    "        self.train_mean_iou.add_batch(\n",
    "            predictions=predicted.detach().cpu().numpy(),\n",
    "            references=masks.detach().cpu().numpy()\n",
    "        )\n",
    "\n",
    "        if batch_nb % self.metrics_interval == 0:\n",
    "            metrics = self.train_mean_iou.compute(\n",
    "                num_labels=self.num_classes,\n",
    "                ignore_index=255,\n",
    "                reduce_labels=False,\n",
    "            )\n",
    "            metrics = {'loss': loss, \"mean_iou\": metrics[\"mean_iou\"], \"mean_accuracy\": metrics[\"mean_accuracy\"]}\n",
    "            for k, v in metrics.items():\n",
    "                self.log(k, v)\n",
    "            return metrics\n",
    "        else:\n",
    "            return {'loss': loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        images, masks = batch['pixel_values'], batch['labels']\n",
    "        outputs = self(images, masks)\n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "\n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits,\n",
    "            size=masks.shape[-2:],\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False\n",
    "        )\n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "\n",
    "        self.val_mean_iou.add_batch(\n",
    "            predictions=predicted.detach().cpu().numpy(),\n",
    "            references=masks.detach().cpu().numpy()\n",
    "        )\n",
    "        self.val_outputs.append({'val_loss': loss})\n",
    "        return {'val_loss': loss}\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics = self.val_mean_iou.compute(\n",
    "            num_labels=self.num_classes,\n",
    "            ignore_index=255,\n",
    "            reduce_labels=False,\n",
    "        )\n",
    "\n",
    "        avg_val_loss = torch.stack([x[\"val_loss\"] for x in self.val_outputs]).mean()\n",
    "        val_mean_iou = metrics[\"mean_iou\"]\n",
    "        val_mean_accuracy = metrics[\"mean_accuracy\"]\n",
    "\n",
    "        metrics = {\"val_loss\": avg_val_loss, \"val_mean_iou\": val_mean_iou, \"val_mean_accuracy\": val_mean_accuracy}\n",
    "        for k, v in metrics.items():\n",
    "            self.log(k, v)\n",
    "\n",
    "        self.val_outputs.clear()\n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, batch, batch_nb):\n",
    "        images, masks = batch['pixel_values'], batch['labels']\n",
    "        outputs = self(images, masks)\n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "\n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits,\n",
    "            size=masks.shape[-2:],\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False\n",
    "        )\n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "\n",
    "        self.test_mean_iou.add_batch(\n",
    "            predictions=predicted.detach().cpu().numpy(),\n",
    "            references=masks.detach().cpu().numpy()\n",
    "        )\n",
    "        self.test_outputs.append({'test_loss': loss})\n",
    "        return {'test_loss': loss}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        metrics = self.test_mean_iou.compute(\n",
    "            num_labels=self.num_classes,\n",
    "            ignore_index=255,\n",
    "            reduce_labels=False,\n",
    "        )\n",
    "\n",
    "        avg_test_loss = torch.stack([x[\"test_loss\"] for x in self.test_outputs]).mean()\n",
    "        test_mean_iou = metrics[\"mean_iou\"]\n",
    "        test_mean_accuracy = metrics[\"mean_accuracy\"]\n",
    "\n",
    "        metrics = {\"test_loss\": avg_test_loss, \"test_mean_iou\": test_mean_iou, \"test_mean_accuracy\": test_mean_accuracy}\n",
    "        for k, v in metrics.items():\n",
    "            self.log(k, v)\n",
    "\n",
    "        self.test_outputs.clear()\n",
    "        return metrics\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam([p for p in self.parameters() if p.requires_grad], lr=2e-05, eps=1e-08)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.train_dl\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.val_dl\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.test_dl\n",
    "\n",
    "feature_extractor = SegformerImageProcessor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
    "feature_extractor.reduce_labels = False\n",
    "feature_extractor.size = 128\n",
    "\n",
    "train_dataset = SemanticSegmentationDataset(f\"{dataset.location}/train/\", feature_extractor)\n",
    "val_dataset = SemanticSegmentationDataset(f\"{dataset.location}/valid/\", feature_extractor)\n",
    "test_dataset = SemanticSegmentationDataset(f\"{dataset.location}/test/\", feature_extractor)\n",
    "\n",
    "batch_size = 8\n",
    "num_workers = 4\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "segformer_finetuner = SegformerFinetuner(\n",
    "    train_dataset.id2label,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    metrics_interval=10,\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.00,\n",
    "    patience=10,\n",
    "    verbose=False,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(save_top_k=1, monitor=\"val_loss\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    devices=1,\n",
    "    callbacks=[early_stop_callback, checkpoint_callback],\n",
    "    max_epochs=500,\n",
    "    val_check_interval=len(train_dataloader),\n",
    "    num_sanity_val_steps=0,\n",
    ")\n",
    "\n",
    "trainer.fit(segformer_finetuner)\n",
    "\n",
    "trainer.test(segformer_finetuner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
